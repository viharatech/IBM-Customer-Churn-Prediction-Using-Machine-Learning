# ğŸ“Š IBM Customer Churn Prediction Using Machine Learning

## ğŸ“˜ Project Overview

This project aims to predict **customer churn** for a telecom company using the **IBM Sample Dataset**.
The objective is to identify which customers are likely to discontinue services, enabling proactive retention strategies.

We conducted **Exploratory Data Analysis (EDA)**, **Feature Engineering**, **Data Balancing**, **Model Training**, and **Web Deployment** using modern data science techniques.

---

## ğŸ“‚ Dataset Overview

* **Source:** IBM Sample Telco Customer Churn Dataset
* **Rows:** 7043
* **Columns:** 21 features + Target (`Churn`)
* **Target Variable:** `Churn` (Yes = Customer left, No = Customer stayed)

### Key Features

| Feature                              | Description                          |
| ------------------------------------ | ------------------------------------ |
| Gender                               | Male / Female                        |
| Partner / Dependents                 | Customer relationship info           |
| InternetService                      | DSL / Fiber optic / None             |
| PaymentMethod                        | Electronic check, Credit card, etc.  |
| Contract                             | Month-to-month / One year / Two year |
| Tenure, MonthlyCharges, TotalCharges | Numeric variables                    |
| Churn                                | Target variable (Yes/No)             |

---

## âš™ï¸ Workflow Summary

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)

* Visualized **demographic trends** and **service usage** patterns.
* Observed that:

  * Customers without dependents and partners churned more.
  * Fiber optic customers had higher churn rates.
  * Month-to-month contracts had maximum churn.

### 2ï¸âƒ£ Handling Missing Values

Used multiple techniques and finalized **IterativeImputer** for robust imputation:

* `KNNImputer`
* `SimpleImputer`
* `IterativeImputer`
* `MeanMedianImputer`
* `ArbitraryNumberImputer`
* `RandomSampleImputer`

**Finalized:** `IterativeImputer` (DecisionTreeRegressor model) â€” due to better statistical consistency and performance.

---

### 3ï¸âƒ£ Variable Transformation

Performed data transformation to improve model interpretability and reduce skewness.
Tested:

* Log, SquareRoot, CubeRoot, Power, Quantile, and Tanh transforms.

**Finalized:** `QuantileTransformer` (Normal distribution)
â†’ Produced bell-curve-like distribution and reduced skewness effectively.

---

### 4ï¸âƒ£ Outlier Handling

Techniques compared:

* **Winsorizer (IQR, Gaussian, Quantile, MAD)**
* **Isolation Forest**
* **Quantile Clipping (0.01â€“0.99)**

**Finalized:** `Gaussian Winsorizer` â†’ smooth, symmetric capping aligned with scaled numeric data.

---

### 5ï¸âƒ£ Encoding Categorical Features

Applied a hybrid approach:

| Type                 | Method                               | Example Columns                         |
| -------------------- | ------------------------------------ | --------------------------------------- |
| **Ordinal Encoding** | Contract                             | Month-to-month < One year < Two year    |
| **One-Hot Encoding** | InternetService, PaymentMethod, etc. | Categorical variables                   |
| **Manual Mapping**   | sim                                  | {'Jio':0, 'Airtel':1, 'Vi':2, 'BSNL':3} |
| **Label Encoding**   | Target (Churn)                       | Yes â†’ 1, No â†’ 0                         |

---

### 6ï¸âƒ£ Feature Selection

Applied **Filter Methods**:

* VarianceThreshold
* Chi-Square Test
* ANOVA F-Test
* t-Test
* SelectKBest

These helped retain only statistically significant features with the highest predictive power.

---

### 7ï¸âƒ£ Correlation & Hypothesis Testing

* Used Pearson correlation to remove multicollinearity (r > 0.85).
* Conducted **ChiÂ², t-Test, ANOVA** to validate feature significance.

---

### 8ï¸âƒ£ Balancing the Dataset

Used **SMOTE (Synthetic Minority Oversampling Technique)** from `imblearn`:

* Balanced Churn vs Non-Churn ratio from **27% : 73%** to **50% : 50%**
* Resulted in better recall and F1-score for churn detection.

---

### 9ï¸âƒ£ Feature Scaling

Used **StandardScaler** for standardization:

[
z = \frac{x - \mu}{\sigma}
]

* Mean = 0, Standard Deviation = 1
* Ensures equal contribution of all numeric features.
* Works best with algorithms like Logistic Regression & SVM.

---

### ğŸ”Ÿ Model Training & Evaluation

#### Models Tested

| Model               | Type           | Key Trait                       |
| ------------------- | -------------- | ------------------------------- |
| Logistic Regression | Linear         | Fast, interpretable             |
| KNN Classifier      | Distance-based | Simple but sensitive to scaling |
| GaussianNB          | Probabilistic  | Handles high-dimensional data   |
| Decision Tree       | Tree-based     | Easy to interpret               |
| Random Forest       | Ensemble       | Robust, less overfitting        |
| XGBoost             | Boosting       | High accuracy                   |
| SVC                 | Margin-based   | Works well for non-linear data  |
| Gradient Boosting   | Boosting       | High predictive power           |

#### Metrics Used

* Accuracy
* Precision
* Recall
* F1-Score
* ROCâ€“AUC Score

#### Example Results

| Model               | Accuracy | ROC-AUC |
| ------------------- | -------- | ------- |
| Logistic Regression | 0.75     | 0.86    |
| Random Forest       | 0.71     | 0.66    |
| XGBoost             | 0.69     | 0.67    |
| Gradient Boosting   | 0.79     | 0.86    |

**Finalized Model:** Gradient Boosting Classifier

> Balanced accuracy, interpretability, and computational efficiency.

---

## ğŸ“ˆ ROC and AUC

* ROC curve demonstrates modelâ€™s ability to distinguish between churn and non-churn.
* AUC close to **0.86â€“0.88** indicates excellent discriminative capability.

---

## ğŸŒ Model Deployment

### Platform

* **Backend:** Flask
* **Hosting:** Render Cloud Platform

### Deployment Workflow

1. Trained model & scaler saved as `model.pkl` and `scaler.pkl`.
2. Flask app built to handle user inputs and predictions.
3. Auto-deployed via GitHub â†’ Render integration.
4. Live churn prediction available through web interface.

---

## ğŸ§° Tools & Libraries

* **Python 3.9+**
* **NumPy, Pandas, Matplotlib, Seaborn**
* **scikit-learn**
* **feature-engine**
* **imblearn**
* **xgboost**
* **Flask**
* **Render (for deployment)**

---

## ğŸ“Š Key Insights

* Customers with **month-to-month contracts** churn more frequently.
* **Fiber optic** users have higher churn rates.
* Customers **without dependents or partners** are more likely to leave.
* **Electronic check** payment method correlates with higher churn.
* **Tenure** and **contract length** are strong churn predictors.

---

## ğŸš€ Results Summary

* AUC â‰ˆ **0.88**
* Accuracy â‰ˆ **79%**
* Balanced recall and precision after SMOTE
* Smooth, explainable prediction pipeline

---

## ğŸ‘¨â€ğŸ’» Author

**Madhala. Siva Narayana Surya Chandra**
Machine Learning Enthusiast | Data Science Practitioner

For support : sivanarayana9347@gmail.com 
Find the Project here : https://ibm-customer-churn-prediction-using.onrender.com


